{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import clip_grads, convert_one_hot, preprocess, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 0, 6, 7, 1, 2]),\n",
       " array([[3, 0],\n",
       "        [4, 6],\n",
       "        [0, 7],\n",
       "        [6, 1],\n",
       "        [7, 2],\n",
       "        [1, 5]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "\n",
    "    ###<your code>###\n",
    "    contexts = corpus[window_size:-window_size]\n",
    "    targets = []\n",
    "    \n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx+t])\n",
    "        targets.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "contexts, targets= create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0]]),\n",
       " array([[[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0]],\n",
       " \n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0]]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "### <your code> ###\n",
    "contexts = convert_one_hot(contexts,len(word2idx))\n",
    "targets = convert_one_hot(targets,len(word2idx))\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in)\n",
    "        self.out_layer = Dense(W_out)\n",
    "        self.loss_layers = [SoftmaxWithCrossEntropy() for i in range(window_size*2)]\n",
    "        \n",
    "\n",
    "        layers = [self.in_layer, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts)\n",
    "        s = self.out_layer.forward(h)\n",
    "        \n",
    "        loss = sum([self.loss_layers[i].forward(s, targets[:, i]) for i in range(self.window_size*2)])\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        ds = sum([self.loss_layers[i].backward(dout) for i in range(self.window_size*2)])\n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████                                                                | 170/1000 [00:00<00:00, 1478.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.158890702827621\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.158911151381153\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.159017918135207\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.158969434211409\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.158751373785917\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.158744380149681\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158708077506387\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.158741885343449\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.158641655168464\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.158583298551681\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158538082497183\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.1586065032474515\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.1582489730799175\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.158461442858474\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.158097338886107\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.158237600379984\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.1583031487608455\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.157826845000677\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.15789944514561\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.157669194105265\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.157702222169723\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.1575481138734185\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.157293735685751\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.157318608876579\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.156730800828164\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.157136119929328\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.1561855766356075\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.156102582017495\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.156591697362702\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.1554872560479685\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.155246375663564\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.154054323876178\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.155745564903772\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.153394825397738\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.153805977534652\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.152817969811288\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.151510496917723\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.1512633840051345\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.1498751111669145\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.149719707115413\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.147711007607277\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.147668900923903\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.147197329139463\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.142810313363091\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.141502332603504\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.140110959594587\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.138752853276785\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.138542247063604\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.130930594584634\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.127150814377214\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.126792491265798\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.125374529589752\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.119462075492617\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.121234598481159\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.102462601823883\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.10743417783157\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.099029621942863\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.08605936737439\n",
      "Epoch: 59, Iteration: 1/2, Loss: 4.0828969862165\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.067170545958589\n",
      "Epoch: 61, Iteration: 1/2, Loss: 4.07004936007742\n",
      "Epoch: 62, Iteration: 1/2, Loss: 4.06291630517579\n",
      "Epoch: 63, Iteration: 1/2, Loss: 4.029496204932815\n",
      "Epoch: 64, Iteration: 1/2, Loss: 4.031266759016622\n",
      "Epoch: 65, Iteration: 1/2, Loss: 4.014330077120591\n",
      "Epoch: 66, Iteration: 1/2, Loss: 3.995487367561791\n",
      "Epoch: 67, Iteration: 1/2, Loss: 3.9732914023035795\n",
      "Epoch: 68, Iteration: 1/2, Loss: 3.9641472680452865\n",
      "Epoch: 69, Iteration: 1/2, Loss: 3.9539478478000327\n",
      "Epoch: 70, Iteration: 1/2, Loss: 3.876997883932016\n",
      "Epoch: 71, Iteration: 1/2, Loss: 3.92403404089956\n",
      "Epoch: 72, Iteration: 1/2, Loss: 3.8449006943083632\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.808435290689053\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.8247002587731185\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.7647835943589167\n",
      "Epoch: 76, Iteration: 1/2, Loss: 3.7326484830341675\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.6925945151927975\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.6372193430649444\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.64839499699462\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.4390481028781874\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.596860279325784\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.4809759006656043\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.3618627797886376\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.3617349410684696\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.39350970748752\n",
      "Epoch: 86, Iteration: 1/2, Loss: 3.3051965834763863\n",
      "Epoch: 87, Iteration: 1/2, Loss: 3.055325225694461\n",
      "Epoch: 88, Iteration: 1/2, Loss: 3.233757615019279\n",
      "Epoch: 89, Iteration: 1/2, Loss: 3.186654698682201\n",
      "Epoch: 90, Iteration: 1/2, Loss: 2.982759739468113\n",
      "Epoch: 91, Iteration: 1/2, Loss: 3.1190134953326463\n",
      "Epoch: 92, Iteration: 1/2, Loss: 3.062690551692623\n",
      "Epoch: 93, Iteration: 1/2, Loss: 2.769793383214698\n",
      "Epoch: 94, Iteration: 1/2, Loss: 2.8405989137968106\n",
      "Epoch: 95, Iteration: 1/2, Loss: 3.031240037067663\n",
      "Epoch: 96, Iteration: 1/2, Loss: 2.8312578258607957\n",
      "Epoch: 97, Iteration: 1/2, Loss: 2.7266349379715464\n",
      "Epoch: 98, Iteration: 1/2, Loss: 2.636447717716785\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.702638209918244\n",
      "Epoch: 100, Iteration: 1/2, Loss: 2.5879943388985343\n",
      "Epoch: 101, Iteration: 1/2, Loss: 2.6220148789378834\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.5733805662716422\n",
      "Epoch: 103, Iteration: 1/2, Loss: 2.6362591279628047\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.503893681242431\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.398871554261469\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.4983844334605196\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.399465648377587\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.2612962790426545\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.4688946779600784\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.249549617550823\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.2787905530753907\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.2379527485613\n",
      "Epoch: 113, Iteration: 1/2, Loss: 2.231116898173287\n",
      "Epoch: 114, Iteration: 1/2, Loss: 2.154400858018488\n",
      "Epoch: 115, Iteration: 1/2, Loss: 2.1227239932920168\n",
      "Epoch: 116, Iteration: 1/2, Loss: 2.1627178551169495\n",
      "Epoch: 117, Iteration: 1/2, Loss: 2.068536963963487\n",
      "Epoch: 118, Iteration: 1/2, Loss: 2.0642052988983064\n",
      "Epoch: 119, Iteration: 1/2, Loss: 2.093283583631705\n",
      "Epoch: 120, Iteration: 1/2, Loss: 2.036074154876622\n",
      "Epoch: 121, Iteration: 1/2, Loss: 1.9633347904414444\n",
      "Epoch: 122, Iteration: 1/2, Loss: 2.028752192667505\n",
      "Epoch: 123, Iteration: 1/2, Loss: 1.9381284851864191\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.961835435170479\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.9187954998765884\n",
      "Epoch: 126, Iteration: 1/2, Loss: 1.9010983277193134\n",
      "Epoch: 127, Iteration: 1/2, Loss: 1.899917772209068\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.8611029711373663\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.866106108931644\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.8496783393301404\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.8210025158657839\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.8204064216388605\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.8018354976820872\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.778192094420597\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.7621730827542046\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.764284952103956\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.7428153094682142\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.7319663062732107\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.7459940960683258\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.6986451474650939\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.707221376175807\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.7029088154716188\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.6733649666218198\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.6931045171832904\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.6631577827212962\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.6698923247133823\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.648936756616746\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.6268065487135874\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.658612880814454\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.630558770974716\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.638978307297959\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.608861637911955\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.6118121375371035\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.6234439412265065\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.585777709456158\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.5911441182202704\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.5937069821373657\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.5678166883408784\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.5951893488026212\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.5759748971603171\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.5717635323843984\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.5802594035589959\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.5511277951442193\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.556974706130698\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.5526129127584085\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.5538546910799025\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5450433131076065\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.5321747047945165\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.5507744325989274\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.52696159295867\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.557629654494126\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.5067555048753651\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.528553688643234\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.535223716891016\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.5214286917957012\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.5083005407592098\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.5363217639203346\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.4944363424874478\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.5216934008450171\n",
      "Epoch: 180, Iteration: 1/2, Loss: 1.518632834919027\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.5053111352517932\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.504276998494413\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.4936530004877078\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.4991041133218075\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.4887991776259009\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.5051246158289646\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.502157075576978\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.4841637559746232\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.4908560986428678\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.4870277122749334\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.4872930951324987\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.492145015936338\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.476315292262047\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.481697463683048\n",
      "Epoch: 195, Iteration: 1/2, Loss: 1.4804999290040612\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.4782567216181977\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4700447889743675\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.482117566007592\n",
      "Epoch: 199, Iteration: 1/2, Loss: 1.4756740604567387\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.4793397809317794\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.4636485421893806\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.4652296311892066\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.46942455408505\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.4678329571481088\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.4783027479157773\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.45410608731234\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.4646135525549338\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4631849674727295\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.4729644214563091\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.4566247648943786\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.4539861977357829\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.464127955977689\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.4572261115192184\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.4571673598389272\n",
      "Epoch: 215, Iteration: 1/2, Loss: 1.4556920206711599\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.4553306163411672\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.4551208311125876\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.4575503743646303\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.4485071174421689\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.4515468397566593\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.4455731798676559\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.4547955098675844\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.4440622375692524\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.452400071927896\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.4525045716870915\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.4381036583514533\n",
      "Epoch: 227, Iteration: 1/2, Loss: 1.4547018980916662\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.4454097004814817\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.4401705064369024\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.445020811931598\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.4465931566235515\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.4426509610399447\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.4345431062412546\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.4445809061173018\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.4418566269148818\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.4393757406143441\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.4429879466275604\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.4359287895445467\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.4340103689474084\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.4382730618911497\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.4370457160477352\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4436465959635014\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.4363137604331078\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4321730550777902\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.4383743641718771\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.4341002843102397\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.4314022587293032\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.433163939340988\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.4360192341243752\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.432969092719405\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.428172086722399\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.4355371868650917\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.4308120980167178\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.4307534342611616\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.4277150201768327\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.42972609971492\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.4323224122381466\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.4265737722327374\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.4252172908139982\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.428299707228907\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.4334766241650017\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.4246611186781748\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.429842067608011\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.4212949264252346\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.4288316434805475\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.4258244029189724\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.4256097861470587\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.4252553143238247\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.42576359787335\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.4266003886097665\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.4195119306034785\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.426453651868047\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.42372251241502\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.4225317891570457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████                                       | 495/1000 [00:00<00:00, 1500.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 275, Iteration: 1/2, Loss: 1.4237717721463747\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.4197560160921736\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.4271794663335637\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.4193292399604198\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.4196986539685965\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.4237639806447993\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.4204634430578995\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.423391147075586\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.4205255281666185\n",
      "Epoch: 284, Iteration: 1/2, Loss: 1.4161174751462138\n",
      "Epoch: 285, Iteration: 1/2, Loss: 1.4218965456663164\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.4220296626919944\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4193263157560048\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.4192882314516888\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4165022761533526\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4191471666755042\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.4161843622249268\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.4199119612226943\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.418640853267223\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.4169428386931362\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.419610418142156\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.4155054540809084\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.4147016860829253\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.416985191524188\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.4180521927196956\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.4167273001340321\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.4155038947433651\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.414364379078811\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4178736716616633\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.41518519645795\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.4147443618054676\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.4169778795854957\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.4114054976105355\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.4164295198045442\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.4140596367261793\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.414602911371932\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.4119762622834435\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.4151603781218325\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.4136008871141188\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.4140203281415724\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.4127222046916432\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4117441291319608\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.4146763647271774\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.4122798666640004\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.4111070994540347\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.4140081631713253\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4104191583443273\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4136388309981054\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.4119929879579365\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.4112728668902728\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.4118468130638964\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.4108204050639739\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.412841141308862\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.411077115837276\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.409385182232731\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.4104862228304014\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.4109621984363931\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.4097991431126098\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.4118534126562892\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.4101288248624355\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.4083518493463345\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.409669611695218\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.4111863369465374\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.4080152604087437\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.4096154096694402\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4091931898474737\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.4091307982605477\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.4086552288008825\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4102995523268942\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4086501283881734\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.406963275903573\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4071694667758219\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.4094583662476912\n",
      "Epoch: 348, Iteration: 1/2, Loss: 1.409492497393172\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.4066392223175865\n",
      "Epoch: 350, Iteration: 1/2, Loss: 1.4067626224854002\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4077622692080638\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.4089721382314195\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.407167855120028\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.4077312374778037\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4084670833393453\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.406004095847384\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.4070287203058292\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.406496382773497\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.40722254111487\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.4076051616146794\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.4055520444561576\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.4074710666532515\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.4063196514022818\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.4053036135913057\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.4058315792864593\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.4063712193327038\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.4057538249789023\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.4046082050958133\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4078711855258375\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.4046377711320395\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4041493743245015\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.4077332458356615\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.4039206145454557\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.4052510872354067\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.406314288873835\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.4041480384541525\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.4048712792501512\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.4045669603860094\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.4058364160986547\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.4036246915895154\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4033874143799445\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.406512315664017\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.4031735352629444\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.4044420554009922\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.4041213986960328\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4041492579497064\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.4028041476009767\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.4046884699300466\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.4049443912182866\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.402672718439999\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.4034502335923242\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.4038629614846068\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.4023754228833534\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.4043828571106995\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.4041613515795595\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.4033279626806126\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.4018882765860001\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.4023000790682862\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.4037206949495444\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.4021332982929011\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.4036586014360046\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.4036897665440733\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.4015242039816993\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.4027222751216533\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.4023899599023038\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.4023996630795348\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.4016185386725648\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.4030611109999702\n",
      "Epoch: 409, Iteration: 1/2, Loss: 1.4022102560799503\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.4023703474174187\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.401978292583597\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.4009717693558208\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.4019608939638593\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.4025839537561189\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.402746577269187\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.400975534498138\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.401360719929809\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.4015069128175737\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.4016852415650267\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.4014483255922698\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.4011972329652267\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.4005074695052244\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.4020038574998979\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.4020531114282022\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.3994740482546522\n",
      "Epoch: 426, Iteration: 1/2, Loss: 1.4018774104099034\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.400838557059604\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.4010228430624312\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.4016142916583765\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.3997684579668213\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.4016880465760848\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.400650302001707\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.3998494473037701\n",
      "Epoch: 434, Iteration: 1/2, Loss: 1.4005523533518631\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.4011581246685165\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.3988908448493702\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.401063216257127\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.4011094749402848\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.4003168257552474\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.3994774924110196\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.3998961380686805\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.4000827737549697\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.4000043607952461\n",
      "Epoch: 444, Iteration: 1/2, Loss: 1.3999480305377323\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.4000670336519274\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.400452458611646\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.399781411255508\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.3997079509418633\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.3990845623097523\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.3987814394278408\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.3995535826584597\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.4000973016082943\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.3988046326610701\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.400122580690169\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.3994848797364219\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.3985649242060019\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.3998816734353405\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.3999718566477448\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.3983662753057842\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.398408916516458\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.3999846392815631\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.398926283533279\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.3981606026590696\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.3997702947139166\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.3985628644930845\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.3988625103732322\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.398974311996843\n",
      "Epoch: 468, Iteration: 1/2, Loss: 1.3986220612936249\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.3979473006250969\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.3991407688769357\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.3987683612037423\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.3985968226900716\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.3984275206978833\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.399101083367\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.3983176858360498\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.3970182883035247\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.3990860572529862\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.3988074536090416\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.3982629576098775\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.3975829062795708\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.3980374857951672\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.3973816071828193\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.3988050986408909\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3979283686279147\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.397780251851698\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.398096475523205\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3977492863406868\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.3972465412329402\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.3978210476820152\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.3983076760278634\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.3978708918967064\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.3969408285165024\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.3980978652670095\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.398379484013154\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.3969942234553008\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.3972431864479615\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.397527886936249\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.3976319377062643\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3971940892271046\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.3972827019224328\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3973881631642406\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.397903993512208\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.3966994162008721\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3972113422472585\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.39773236641355\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.3958335380257882\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.3978318546621042\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.3975855900558298\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.396476130581992\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.3967442938923176\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.396999395050182\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.397541115747705\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.395719689048445\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.3973725667899533\n",
      "Epoch: 515, Iteration: 1/2, Loss: 1.3962158163353453\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.3968398010963088\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.397846227711848\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.3960831087453536\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3966466084972657\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.3967891097912464\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.3959410209407308\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.3971458282026528\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3970039784010964\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.395428130364956\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.3975327845064487\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.395283192193548\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.3975863786871139\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.395214624768196\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.3963549912439972\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.3973361175018475\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.3958386545026413\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.3960716969356732\n",
      "Epoch: 533, Iteration: 1/2, Loss: 1.3963265660657314\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3960517854667212\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3956494215667359\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.3965772948350745\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.3962000301755497\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.3954485336155686\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.397070856178363\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.3959818851213788\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.3949014339290957\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.3965628173938995\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3958382060658427\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.3959033093423763\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.3951670326429193\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.396855759226244\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3952354995219531\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.395279581593932\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.396738991503288\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.3952900138636215\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.3954566547173335\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.3957800871206762\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.3950451961368733\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.3955898582394963\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.396112952765448\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.3949547960213229\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.3964410618843703\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.39507628776286\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.395842268180833\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.394974268462236\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.395788753041756\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.39484068776963\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.395408708459807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████▋             | 827/1000 [00:00<00:00, 1518.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.3951559541566678\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.395842648047274\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.3946871863517707\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.3957786477924172\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.3946305196677964\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.3953180293060488\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.3950613960096017\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.3950702211727148\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.395649258636757\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3950658458446452\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.3950193993322764\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3945309322338675\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.3945587476847967\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.3954700007163163\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.3948229762565667\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.394904034797668\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.3949432888523623\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.394965386291193\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.3947440782089204\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.3944237741542462\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.3952747859530534\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.394693221191674\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.3947273004645155\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.394870257688941\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.3945141685773415\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.3943265184213454\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.39513096841924\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.3945596115477623\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3942163744574834\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.3950448630862844\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.3944911357330696\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.3950074240184724\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.3940285214052963\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.3941079295933037\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.3944912992715772\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.3949626924011373\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.3944197482365144\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.3943485184796747\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.3944243544496393\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.394231507948417\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.3939615369349938\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.3947118442975235\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.394755568465226\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.3939419968186435\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.3946184538808728\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.39418920218742\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.3938450396218978\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.3940497766356708\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.3938358603680034\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.3946411401490888\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.394019028881994\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.3940480264417925\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.3942621192164069\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.393565927271653\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.394011133181551\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.3945217644189225\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.3943454426545503\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.3940356679038397\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.3936112406867067\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3937651064187695\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.3936085718279512\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.39392299894828\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.3946704725410441\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.3930837718237836\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.3946153838814326\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.393531501128372\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.3938026727668924\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.3937420844101618\n",
      "Epoch: 632, Iteration: 1/2, Loss: 1.3933409072331593\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3937521274238032\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.3936949867076565\n",
      "Epoch: 635, Iteration: 1/2, Loss: 1.3940701905820072\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.393683191094398\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.3938044682653776\n",
      "Epoch: 638, Iteration: 1/2, Loss: 1.3939973871654754\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.393218162240073\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.3936992672185173\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.3935176905153261\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.3935833722606845\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.3936322593171595\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.3930997259132156\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.3943272019656594\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.393162136120468\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.393085892401458\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.3934774807317347\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.3937508358129158\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.3934768407244793\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.3930934301461546\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.3937503508039255\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.393341364851735\n",
      "Epoch: 654, Iteration: 1/2, Loss: 1.3938217557602668\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.3933538094569446\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.3925947720562024\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.393722057270955\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.3933381812822478\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3933004967905704\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.3931539613454085\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.3929205392449353\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.3939524266406034\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.3925194753910954\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.3934765142066443\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.3931861170159316\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.3931665467641148\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.393156381063161\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.3935685710753387\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3927959384962678\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.392998981089613\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.39352011762844\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.3923615651761345\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.3937646777457235\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.3927335960308582\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3929376557742927\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.3931295038044214\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.3929468400819736\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.3929051845731641\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.3926260401088184\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.393401091154495\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.3928260519372377\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.3930222152820724\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.392901260862058\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.393187904562326\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.3928276354166431\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.392152506419877\n",
      "Epoch: 687, Iteration: 1/2, Loss: 1.3931725980736034\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.3928385802676024\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.392766384494443\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.3929426279984274\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.392771102757961\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.3923382839469454\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.3934555174578644\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.3920797511970089\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.3929765150298576\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.3927089917310758\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.3927047569710578\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.392712130084395\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.3923333037977228\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.3930423458567311\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.3926687577270513\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.3926339107696675\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.392866166574516\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.3923285397224678\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.3925626872333725\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.3924962061138162\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.3926533679790973\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.3924301057265418\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.392537689288408\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3925710497487214\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.3921479915596977\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.3927767172727439\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.392570190642018\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.3923617637521517\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.3924150963525777\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.3921714572969892\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.3930542424479457\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.3923952386030498\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.3917715376646989\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.3926665642471945\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.3924215734987389\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.391982582764389\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.3927509411758119\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3923156111796025\n",
      "Epoch: 725, Iteration: 1/2, Loss: 1.392229487902993\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.3923565215218736\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3922318833344798\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.3922381250367515\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.392021223887368\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.392615089359276\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.392248933011396\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.391823312247538\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.3924823048955322\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.3925701648704767\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.3918567309211554\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.3925345031306695\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.3917765986509587\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.391914475272551\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.3927328566079589\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3915349166244242\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3924330653710761\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.391748351044118\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.392380763014078\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.3921432165967151\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.3919840112352095\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.3921373323771657\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3923384837956922\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.3917346672338942\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.3919290936474722\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.3920168403354194\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.392334395506377\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.3917644378846064\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.3919724919402245\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.3918344532526419\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.3922939923991038\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.3917104392455157\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.3915840068585652\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.3921782559400526\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.3916420247507924\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.3922090421372242\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3921423116315141\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.3918962257801077\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.3916081343473274\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.3917240413982792\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.3916137760767366\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.3923956501162411\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.3912566836503446\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.392131050364615\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.3920239294742034\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.3915518363740336\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.3914123502043125\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.3920418288998477\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.3918363103759126\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3917299367202758\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.3917027196930192\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.3917524038074833\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.3916720581749416\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.3919735288642607\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.391107076834384\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.391650852051436\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.3916659665708253\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3920152311800975\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.391525023381018\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.3916587711043737\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.3913592300003808\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.3919457013999479\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.391305379531699\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.3918224213762787\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.391591110470822\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.3915389758664158\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.3913508344999999\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.3920829718655343\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.391550877254824\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.3912887256976614\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.3914724161895236\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.3912455970093742\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.3920607852238653\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.390960368622333\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.3917243363344358\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.3914400778720615\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.3912561190725645\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.3914542097251312\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.3917649042570783\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.391114210890629\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.3919496304895125\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.391096215965669\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3914293317520803\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.3916804823437663\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.3913863000671798\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.390865656444266\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.3916516031538362\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.3913091549226295\n",
      "Epoch: 813, Iteration: 1/2, Loss: 1.3914207773593095\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.3912593950233845\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.3914175513046678\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.3912969781000735\n",
      "Epoch: 817, Iteration: 1/2, Loss: 1.3912470275437263\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3913813577936316\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.3915009252077923\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.3910054701021912\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.391044449316393\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3915437008185374\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.3911774658328995\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.391247613298978\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.3910415280279536\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.3915283853366462\n",
      "Epoch: 827, Iteration: 1/2, Loss: 1.3911975704380684\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3912119468009394\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.3914521107747382\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.39117067296803\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.390959329243671\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.3910988246246685\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.3909811371078749\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.391453545419632\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.390848673858105\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.391628121626255\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.3906476872287523\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.391609052404339\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.390824326408194\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.391137479132042\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.3911739523146172\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.3910676028567366\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.391081167107045\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.3912854522246638\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.3908668704987832\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.391056328753763\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.3909796659659701\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.391296243868339\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.390820836014572\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.3909696242851886\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.3912838166233792\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3907226068330756\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.390781957283825\n",
      "Epoch: 854, Iteration: 1/2, Loss: 1.3911988893228369\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.3909893563582436\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.3909952798323697\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.3909440657008532\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.3909576208700336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1518.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.3912300682039\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.390941202032143\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.3906466129615138\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3909320100683895\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.3909318275238463\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.3907116064680658\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.390895405567482\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.3911053489725078\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.3909296058333664\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.3906225897270073\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.3908716163720862\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.3911163014915688\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.3908609983709879\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.3910486031589073\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3906305789072113\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.390780114214694\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.3911026610317123\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.3908159022110957\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.390780178170163\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.3908007402460223\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3905436008270669\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.3908638498940986\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.39069964463625\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.3905514671921415\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.3907914009437365\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.391221543882113\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.3902762533852857\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.3911911482628865\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.390734274488775\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.3905293606690474\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.3909145903179287\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.39043828036631\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.3905095404197843\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.3909620713109008\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.390626110561421\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.3909390415778908\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.3902383011503376\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.3911103236422413\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3904128770778077\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.3906604473670652\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.3907078389415692\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.3903793828599902\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.390878635984691\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.3908094605011798\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3903860056347126\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.3904138967017745\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.3908693684016544\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.3907667481979726\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.3904203559155859\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3905565304827485\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.390338108305559\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.3908061013366897\n",
      "Epoch: 911, Iteration: 1/2, Loss: 1.3903334575430195\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.390737680309878\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.3905293751112957\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.3903743250966643\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.3907276246841815\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.3905023457933123\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3906140953619033\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.390508935024838\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.3904879745953656\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.3906940001262234\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.3903020375124924\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.390422886356274\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.390316314841374\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.390645552221721\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.3902983195327736\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.390460756016541\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.3908942502463477\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.3899915802767808\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.39046783806709\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.3906841438056994\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3903436019332154\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.3902348457538605\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.3904349094629405\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.3904114050445053\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.3905706298907072\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.3904165832854145\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.3903637559762767\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.390455076323596\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.390370620646139\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.390306890310246\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.390186679959581\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.3906272587647317\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.3903522746448873\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.3901032711053556\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.390563150689769\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.3902645484285265\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.390408899895136\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.3900868313726564\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.3907127155044532\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.3901511794816044\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.3900589665304663\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.390452883943445\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.3901350720945103\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.390522241110523\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.390040079251429\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.3905158582846682\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.390005835580339\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.3904965652845156\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.390433585198624\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.3902432428493459\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.3900251404436417\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.3900451454714124\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.3904092081500279\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.390237195157039\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.3900472267078134\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.3902116705452032\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.3902073574789764\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3905928901777336\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.3900437518415742\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.3901828645060523\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3903595692276882\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.3899218787039365\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.3901719831060646\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.3903975445748116\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.3899480390679693\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.389967733501662\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.390317478194825\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.3903731904605938\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3897575024630555\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.3905350617763748\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.3901030788332869\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3899539862172123\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.3902876550991072\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.3898769200984937\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.3901867813184001\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.3900364800547829\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.390301148369053\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.3900888139508463\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.3898491964875972\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.3899281582890106\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.390284362392129\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.390077021546822\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.3900659147819572\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.3900296479546714\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.3900077819619838\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.389880278261666\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.390036651967773\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.3901789804952756\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3900875625899674\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3900261025656258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(vocab_size=len(word2idx), hidden_size=hidden_size, window_size=window_size)\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcdZ3v8fe3lt6ydId0QyCJdGQRAWULMQg6CKiAjIwOKt6LKDgTcWAEd9AZvN7nXh+9eBlheC5cBHFD0CuIyIAKCgOIhDQhJIEACSRAFpImWyfd6aWqvvePc6pT6VQn3ek6fWr5vJ6nnj51zqnT318Fzqd/Z/kdc3dERKR2JeIuQERE4qUgEBGpcQoCEZEapyAQEalxCgIRkRqXiruA0WptbfX29va4yxARqShPP/30m+7eVmxZxQVBe3s7HR0dcZchIlJRzOzV4Zbp0JCISI1TEIiI1DgFgYhIjVMQiIjUOAWBiEiNUxCIiNQ4BYGISI2ruPsI9tXy9du4b/E6kgnb+bLg54T6JM2NaZob62hpStPSlKZ1Yj3ppHJSRKpfzQTBi+u3cd2flo94/fpUgiOmTWLuIVO54F0HM3O/pgirExGJj1Xag2lmz57t+3pnsbuTzTnZ/M/w1d2fZUtPP1t3DLC1Z4DNPQO80rmd+Ss3sWTNVgCuOOMwLn3foeoliEhFMrOn3X12sWU10yMAMDNSSdut0S1NML2lsehnVmzYzrfuXcoPHlrODx5azqNffR9vmaregYhUD/15uxeH7j+R2z4zhy+9/3AA3nvNw1RaL0pEZE8UBCNQl0rwhdMPI500AJ54eWPMFYmIlI6CYBQWf+uDTKpPcfVvl6pXICJVQ0EwCo11ST77nlm83NnNtQ++FHc5IiIloSAYpYtOngXAg8+vj7kSEZHSiDwIzCxpZs+Y2X1FlpmZXW9mK8xssZkdH3U9Y9XcmObCkw7mhTe20ZfJxl2OiMiYjUeP4HJg2TDLzgIOC1/zgBvHoZ4xm9U6AYBfLng95kpERMYu0iAwsxnAh4BbhlnlXOCnHngSaDGzA6OsqRQumHswAE+t3BRzJSIiYxd1j+AHwNeA3DDLpwOFf1avDueVtXQywd8ecxAdqzbHXYqIyJhFFgRmdg6wwd2f3tNqRebtdl2mmc0zsw4z6+js7CxZjWNx3MwW3ujqZUNXb9yliIiMSZQ9gpOBD5vZKuBO4DQz+/mQdVYDMwvezwDWDt2Qu9/s7rPdfXZbW1tU9Y7KO2c0A7q5TEQqX2RB4O5XufsMd28Hzgf+7O4XDFntXuDC8OqhucBWd18XVU2ldPxbpvDW1gn8/MlX4y5FRGRMxv0+AjO7xMwuCd/eD7wCrAB+CPzTeNezrxIJ492HTuWVN7vjLkVEZEzGZfRRd38EeCScvqlgvgOXjkcNUZhYn2ZTdz9LVm/lHeGhIhGRSqM7i0vgY//3ibhLEBHZZwqCMegdyIY/h7s6VkSk/CkIxqAvowAQkcqnIBiD047YH4CD9cQyEalgNfWoylJ7/5EH8M4ZzUxq0NcoIpVLPYIx2m9CHV07MnGXISKyzxQEY9Q6sZ4la7ayZsuOuEsREdknCoIxWhXeUPY/7ns+5kpERPaNgmCMPvc3hwDBISIRkUqkIBij9x95AC1NaZKJYgOpioiUPwVBCbQ0ptncMxB3GSIi+0RBUAJTJtSxqbsv7jJERPaJgqAEDmpuZO0WPaBGRCqTgqAEpk9pZM2WHQSDqYqIVBYFQQkc1NxAfybHxu7+uEsRERk1BUEJHNTSCMBa3VQmIhVIQVACCgIRqWQKghJonVgPwKZuXUIqIpVHQVACLU1pADb36ByBiFQeBUEJNKSTAFzzhxdjrkREZPQUBCIiNU5BUCLnnTAj7hJERPaJgqBEDmxuAGCLzhOISIVREJRIKhF8lR/5P0/EXImIyOgoCEoklQyGoV4ZPqhGRKRSKAhKxPQ4AhGpUAqCEtF4cyJSqSILAjNrMLOnzOxZM3vOzL5dZJ1TzWyrmS0KX1dHVU/UNPKoiFSqVITb7gNOc/ftZpYGHjezB9z9ySHrPebu50RYx7jIKQdEpEJFFgQe/Im8PXybDl9Vu7vMqUcgIhUq0nMEZpY0s0XABuBBd59fZLWTwsNHD5jZUcNsZ56ZdZhZR2dnZ5Ql7zP1CESkUkUaBO6edfdjgRnAHDM7esgqC4GD3f0Y4N+Be4bZzs3uPtvdZ7e1tUVZ8r5Tj0BEKtS4XDXk7luAR4Azh8zvcvft4fT9QNrMWsejplJTDIhIpYryqqE2M2sJpxuBM4AXhqwzzSy4At/M5oT1bIyqpijpHIGIVKoorxo6EPiJmSUJdvC/cvf7zOwSAHe/CTgP+LyZZYAdwPleoddhzpzSFHcJIiL7JMqrhhYDxxWZf1PB9A3ADVHVMJ4+ceJM7lzwOkvWbI27FBGRUdGdxSViZpx+xP5kc85ANhd3OSIiI6YgKKH8k8q+98ALe1lTRKR8KAhKqKEuCIJbHl8ZcyUiIiOnICih+pS+ThGpPNpzldBRB02OuwQRkVFTEJTQUQc185l3tzO5IcqrckVESktBUGIT6pN092c1LLWIVAwFQYk11aXI5py+jC4hFZHKoCAoscbwEtId/dmYKxERGRkFQYmlw4fYZzQutYhUCAVBiSUTwVeaVRCISIVQEJRYarBHoHMEIlIZFAQllkoEQbB8/fa9rCkiUh4UBCWWDIPgoh8viLkSEZGRURCUWDqpr1REKov2WiWW7xGIiFQKBUGJ5S8fFRGpFAqCEstfPgpomAkRqQgKghJLFRwa0r0EIlIJFAQlVhgEurtYRCqBgqDECk8Wb90xEGMlIiIjoyAoscI+wIeufzy2OkRERkpBUGKF54ff3N4XXyEiIiOkICixnK4UEpEKoyAoMeWAiFQaBUGJ6d4BEak0CoISm92+X9wliIiMSmRBYGYNZvaUmT1rZs+Z2beLrGNmdr2ZrTCzxWZ2fFT1jJe6VILvfOQdg+8/dP1jMVYjIrJ3qQi33Qec5u7bzSwNPG5mD7j7kwXrnAUcFr7eBdwY/qxohSeMn1vbFWMlIiJ7F1mPwAP5p7Okw9fQA+jnAj8N130SaDGzA6OqabzoyiERqSSRniMws6SZLQI2AA+6+/whq0wHXi94vzqcN3Q788ysw8w6Ojs7oyu4RDTGkIhUkkiDwN2z7n4sMAOYY2ZHD1ml2JjNu+1F3f1md5/t7rPb2tqiKLWkznj7AXGXICIyYuNy1ZC7bwEeAc4csmg1MLPg/Qxg7XjUFKWZ+zXxhdMOjbsMEZERifKqoTYzawmnG4EzgBeGrHYvcGF49dBcYKu7r4uqpvFU+FwCEZFyFuVVQwcCPzGzJEHg/Mrd7zOzSwDc/SbgfuBsYAXQA1wUYT3jKqUnlYlIhYgsCNx9MXBckfk3FUw7cGlUNcRJzy4WkUqh4xcRSdrOINCwEyJSzhQEEUnqkZUiUiEUBBEpPEegR1aKSDlTEESksEcwkM3FWImIyJ6NKAjM7HIzmxxe5nmrmS00sw9EXVwlKzxHMJBVj0BEytdIewQXu3sX8AGgjeAyz+9GVlWVUY9ARMrZSIMg/+ft2cBt7v4sxYeHkNCOgezgdN+AgkBEytdIg+BpM/sjQRD8wcwmAdq77UFP/84g6BnIxFiJiMiejfSGss8CxwKvuHuPme1HFd0FHIXuvp07/8JQEBEpNyPtEZwEvOjuW8zsAuBfgK3RlVX5Cnf+OxQEIlLGRhoENwI9ZnYM8DXgVeCnkVVVBU46ZOrgtHoEIlLORhoEmXBcoHOB69z9OmBSdGVVvg8eNY3fXXYKAD39OkcgIuVrpOcItpnZVcCngPeEI4qmoyurOrROqgPUIxCR8jbSHsEnCB5Gf7G7v0HwOMlrIquqSjTVBTmrIBCRcjaiIAh3/rcDzWZ2DtDr7jpHsBdNdUkAfjH/1ZgrEREZ3kiHmPg48BTwMeDjwHwzOy/KwqpBOhl8vS93duvKIREpWyM9R/BN4ER33wDBYyiBh4BfR1VYtenLZGkMewgiIuVkpOcIEvkQCG0cxWeFXYecEBEpJyPtEfzezP4A3BG+/wTB84ZlhHo13pCIlKmRniz+KnAz8E7gGOBmd/96lIVVm/Nv/iubu/vjLkNEZDcjPrzj7ne5+5fc/Yvu/psoi6omH589A4D1XX3cueD1mKsREdndHoPAzLaZWVeR1zYz6xqvIivZR4+fMThdl9JpFREpP3s8R+DuGkZijAofSlOvIBCRMqQ9U8RmTmkanFaPQETKkfZMEWtvncAR04KOVX9GVw6JSPlREIyDO/5xLgC9updARMqQgmAcTKgPTsUoCESkHEUWBGY208weNrNlZvacmV1eZJ1TzWyrmS0KX1dHVU+c0kkjYbqpTETK00jvLN4XGeDL7r4wfNj902b2oLs/P2S9x9z9nAjriJ2Z0ZhOqkcgImUpsh6Bu69z94Xh9DZgGcFzDGpSd3+WWx5fSee2vrhLERHZxbicIzCzduA4YH6RxSeZ2bNm9oCZHTXM5+eZWYeZdXR2dkZYafSeeW1z3CWIiOwi8iAws4nAXcAV7j70buSFwMHufgzw78A9xbbh7je7+2x3n93W1hZtwRGb97OndRmpiJSVSIPAzNIEIXC7u989dLm7d7n79nD6fiBtZq1R1lQO1m3dEXcJIiKDorxqyIBbgWXufu0w60wL18PM5oT1bIyqJhER2V2UVw2dDHwKWGJmi8J53wDeAuDuNwHnAZ83swywAzjf3T3CmsqCYXGXICIyKLIgcPfHYc97PHe/AbghqhrKVa76s05EKojuLI5BJqeTxSJSPhQE4yQ/3hDAQFY9AhEpHwqCcTL3rfsNTmcUBCJSRhQE4yS8OAqAAR0aEpEyoiCIgXoEIlJOFAQxyGTVIxCR8qEgiMFATj0CESkfCoIYqEcgIuVEQRADDUUtIuVEQRCDK+9eEncJIiKDFAQiIjVOQTCObrvoxLhLEBHZjYJgHL3vbfvz98fPAGD5+m0xVyMiElAQjLOLT2kHYMWG7fEWIiISUhCMs+bGNADbejMxVyIiElAQjLNJ9WEQ9CkIRKQ8KAjG2YT6JADb1SMQkTKhIBhnqWTwlf/bQy/x2saemKsREVEQxKrj1U1xlyAioiCI08T6yB4ZLSIyYgqCGGU0CqmIlAEFQQzuvexkALp15ZCIlAEFQQymtzQC8NVfL2Zzd3/M1YhIrVMQxGBCwbmBNVt2xFiJiIiCIBb1qZ1fe09/NsZKREQUBLEwM/71nCMB2LpjIOZqRKTWRRYEZjbTzB42s2Vm9pyZXV5kHTOz681shZktNrPjo6qn3Jzx9v0BuH/JupgrEZFaF2WPIAN82d3fDswFLjWzI4escxZwWPiaB9wYYT1lJT/43G+eWUNPv64eEpH4RBYE7r7O3ReG09uAZcD0IaudC/zUA08CLWZ2YFQ1lZNJDenBaZ0nEJE4jcs5AjNrB44D5g9ZNB14veD9anYPC8xsnpl1mFlHZ2dnVGWOq2TCBqd7+hQEIhKfyIPAzCYCdwFXuHvX0MVFPrLb7bbufrO7z3b32W1tbVGUGatuHRoSkRhFGgRmliYIgdvd/e4iq6wGZha8nwGsjbKmcvTg8+vjLkFEaliUVw0ZcCuwzN2vHWa1e4ELw6uH5gJb3b1mLqP55Jy3AHDtgy/FXImI1LIoewQnA58CTjOzReHrbDO7xMwuCde5H3gFWAH8EPinCOspO39//G6nQ0RExl1k4yC7++MUPwdQuI4Dl0ZVQ7k74eApALQ0pfeypohIdHRncYzMjC+9/3C29Aywvqs37nJEpEYpCGL2N4cHV0Hd/OgrMVciIrVKQRCzY2a2cGBzA+u2ahRSEYmHgqAMJMy4f8kbGoBORGKhICgDx85sAeA/X6qOu6ZFpLIoCMrAdecfS10ywXNrtsZdiojUIAVBGUglE7S3NnHXwtUEV9SKiIwfBUGZePuBk3lzez8vrd8edykiUmMUBGXi8tMPA2DR65tjrkREao2CoEzMap1Ac2Oaha9uibsUEakxCoIyYWYcO7OFX3a8TnefhqUWkfGjICgj+bGHbnh4RcyViEgtURCUkUvfdygANz7yMs+8pnMFIjI+FARlJJkwGtLBP4kGoROR8aIgKDP/8YX3APC7xTXzfB4RiZmCoMzMmNIIwH8sXsefX9AjLEUkegqCMlOfSvLBow4A4OIfd8RcjYjUAgVBGfr2h48enF6+fluMlYhILVAQlKFpzQ2cfOhUAN7/b4+yVIPRiUiEFARl6mcXv2tw+tM/eirGSkSk2ikIylQiYYPTG7v7WbBqU4zViEg1UxCUsTv+ce7g9Mdu+muMlYhINVMQlLGTDpnKvZedPPj+2gdfoncgG2NFIlKNFARl7p0zWrgsHHri+j8t58wfPEoup4fXiEjpKAgqwHknzBicXrWxhyde3hhjNSJSbRQEFaC9dQLf/9gxg+8vuHU+3/jNEq66e0mMVYlItVAQVIjzTpjBK985e/D9L+a/xh1Pvcbza7vYoAHqRGQMIgsCM/uRmW0ws6XDLD/VzLaa2aLwdXVUtVSLRMJY8t8+wNHTJw/OO/v6x5jznT8xkM3FWJmIVLIoewQ/Bs7cyzqPufux4eu/R1hL1ZjUkOa2z8zZbf5nbnsKd51EFpHRiywI3P1RQHdBRaBtUj0/vujEXeb9ZcVGZl11P1fc+YwuMRWRUYn7HMFJZvasmT1gZkcNt5KZzTOzDjPr6OzsHM/6ytapb9uf3112Cv9wyqxd5t+zaC1H/Ovv+cr/e5ZfLniNzd39dPUOxFSliFQCi/Jwgpm1A/e5+9FFlk0Gcu6+3czOBq5z98P2ts3Zs2d7R4eGZ87L5ZzNPf1s683wL/cs5fEVbxZdr6kuyTXnHcPZ75iGmRVdR0Sql5k97e6ziy6LKwiKrLsKmO3uxfdkIQXB3j2x4k1uevQVHn1p997Tie1TmDGliZlTGpnUkGZacwN/e8xBMVQpIuNpT0GQGu9i8sxsGrDe3d3M5hAcptKdUiXw7kNbefehrezoz/LY8k6u/u1zvBFeYrpg1WYWrNq8y/r/fMczNNUl+chx0zGDt02bzFlHT6MxnaSpLqkehEiVi6xHYGZ3AKcCrcB64FtAGsDdbzKzy4DPAxlgB/Ald39ib9tVj2D08v/GOYdkwvjVgtf52l2LR/TZSfUpWifVs/LNbgCuPOsI1mzewQkHT6Grd4BZrRM4dP+JNKVTNDelI2uDiIxNbIeGoqAgKJ2tO4KTyOu7enljay+d2/pYtbGbp1Zuoj+b45nXtox6m3XJBG+Z2kQ6mSBh8NzaLt41az8O2X8i9akEG7r6aG9tYuqEetom1TOQzTGxPkUqaUyoSzGxITX42ebGOuqSiWBZfYruvgwJMxrrkkAQcOqtiIxMWR4akvg1N6YHfx5+wKRh1+sdyNKXyfHMa5s5/IBJPLD0DbK5HI+v2Egu5wxkc0ydWMcLb2wjYUZ3X4apE+tYuqYLgPkrNzF/5diuJE4ljEw42F4yYdSnEgxkc+w/qYGBbI6muiSpZIKpE+ro6c/S3JgmkTBS+VfSSCUSbNjWy5SmOswgnUyQNGNyY5pkwkgmjIQZmWyOVDK4oM4MJtQlSYTLegeyNKSTNIavTM7J5HLUpxJkck4qYfT0Z2lMJ6lLBdtoqkuyYyDLQNapTyVobkyTDb+3+lSwDQMa65L0Z3LUpRIkw7rzv9cg+GlBTUYwPTgPsHA6nUjgBN9Vfr284PPB9rI5pyGdJJPL0ZBK4uG8we2y83dhkCj4bGENu0wDDgxkcyQs+E4Jt5tzJ5VIkE5aWMvuIa5wj4d6BBKp3oHs4E6tL5NjS88AZtDTn2VTdx/9GWdTdz+NdQm6+7Js6ekHgp1EvsfSO5CldyDLig3b6erN0D51AgAvvNHFoftPJJtzunozAPSEvYa+bG5wZzeQzZHNebgzzpFKJOjLZOkbyJFKBgGTyzkD4bruwU5Pg7yWXn4f785g4CQKwiaTzeHh8oQFoZ9fBuweQuwMp4LVcN/5Ph8s7mE8hr87nUxQ7J94aAztnku2x+WJsF35XWs+QPNyng/pneHtDokEpBJ7vqL/k3NmMu+9h+xxneGoRyCxaUgnd5me1rzz/azWCXGUNCx3p/Dvoly443APpvsyORIW/M/a059hx0A23JEZA9ngL/ltvRkSFrS1P5Njx0CWTNbpz2bZ1D3AfhPSEO7EesPPe3juxt3pD4Mo3wPKug/WlfOdO7P8PM/XmZ/OOZmckwh3Lvl1gcGdoBOsn3Unk3XqUgl29GcxC35vYZt324bv+r3kt1VYD+R3sk4264O9kGQi6C1CfkcZtC9o185/g7pUAiNoby5cHpTuYf27/r7COvLyO9di8ssyuRw2ZKfuQ6Jh6DaGbnL33+HkckHdhaGXC2ss7Gnl2+3uMFiT7xZEhQ6Y3LCHpftOQSASyv91lpcY8r9kYajlz1MMdcDkorNFylrcdxaLiEjMFAQiIjVOQSAiUuMUBCIiNU5BICJS4xQEIiI1TkEgIlLjFAQiIjWu4oaYMLNO4NV9/HgrsMfnHVQhtbk2qM21YSxtPtjd24otqLggGAsz6xhurI1qpTbXBrW5NkTVZh0aEhGpcQoCEZEaV2tBcHPcBcRAba4NanNtiKTNNXWOQEREdldrPQIRERlCQSAiUuNqJgjM7Ewze9HMVpjZlXHXUypmNtPMHjazZWb2nJldHs7fz8weNLPl4c8pBZ+5KvweXjSzD8ZX/b4zs6SZPWNm94Xvq729LWb2azN7Ify3PqkG2vzF8L/ppWZ2h5k1VFubzexHZrbBzJYWzBt1G83sBDNbEi673kb74GcffBRe9b6AJPAy8FagDngWODLuukrUtgOB48PpScBLwJHA/wKuDOdfCXwvnD4ybH89MCv8XpJxt2Mf2v0l4BfAfeH7am/vT4B/CKfrgJZqbjMwHVgJNIbvfwV8ptraDLwXOB5YWjBv1G0EngJOIngU8gPAWaOpo1Z6BHOAFe7+irv3A3cC58ZcU0m4+zp3XxhObwOWEfxPdC7BzoPw59+F0+cCd7p7n7uvBFYQfD8Vw8xmAB8CbimYXc3tnUyww7gVwN373X0LVdzmUApoNLMU0ASspcra7O6PApuGzB5VG83sQGCyu//Vg1T4acFnRqRWgmA68HrB+9XhvKpiZu3AccB84AB3XwdBWAD7h6tVw3fxA+BrQK5gXjW3961AJ3BbeDjsFjObQBW32d3XAN8HXgPWAVvd/Y9UcZsLjLaN08PpofNHrFaCoNjxsqq6btbMJgJ3AVe4e9eeVi0yr2K+CzM7B9jg7k+P9CNF5lVMe0MpgsMHN7r7cUA3wSGD4VR8m8Pj4ucSHAI5CJhgZhfs6SNF5lVUm0dguDaOue21EgSrgZkF72cQdDOrgpmlCULgdne/O5y9PuwyEv7cEM6v9O/iZODDZraK4BDfaWb2c6q3vRC0YbW7zw/f/5ogGKq5zWcAK929090HgLuBd1Pdbc4bbRtXh9ND549YrQTBAuAwM5tlZnXA+cC9MddUEuHVAbcCy9z92oJF9wKfDqc/Dfy2YP75ZlZvZrOAwwhONFUEd7/K3We4ezvBv+Of3f0CqrS9AO7+BvC6mb0tnHU68DxV3GaCQ0Jzzawp/G/8dILzX9Xc5rxRtTE8fLTNzOaG39WFBZ8ZmbjPmo/j2fmzCa6oeRn4Ztz1lLBdpxB0AxcDi8LX2cBU4E/A8vDnfgWf+Wb4PbzIKK8uKKcXcCo7rxqq6vYCxwId4b/zPcCUGmjzt4EXgKXAzwiulqmqNgN3EJwDGSD4y/6z+9JGYHb4Pb0M3EA4asRIXxpiQkSkxtXKoSERERmGgkBEpMYpCEREapyCQESkxikIRERqnIJAKpKZPRH+bDez/1LibX+j2O+Kipn9nZldvZd1rglHHl1sZr8xs5aCZcONSPlQ4ciVIsPR5aNS0czsVOAr7n7OKD6TdPfsHpZvd/eJpahvhPU8AXzY3d/cwzofILh5LmNm3wNw96+b2ZEE16LPIRiK4SHgcHfPmtmngRnu/j+jb4VUMvUIpCKZ2fZw8rvAe8xsUTh+fTL863lB+Nfz58L1T7XguQ2/AJaE8+4xs6fDMe/nhfO+SzDi5SIzu73wd1ngmnB8/CVm9omCbT9iO58XcHt+PHgz+66ZPR/W8v0i7Tgc6MuHgJn91swuDKc/l6/B3f/o7pnwY0+yc0iBPY26eS/wyRJ83VLlUnEXIDJGV1LQIwh36Fvd/UQzqwf+YmZ/DNedAxwd7jABLnb3TWbWCCwws7vc/Uozu8zdjy3yuz5KcIfvMUBr+JlHw2XHAUcRjPHyF+BkM3se+AhwhLt74eGcAicDCwvezwtrXgl8GZhb5DMXA78Mp6cTBEPe4MiT7r45HI5gqrtvLLIdEUA9Aqk+HwAuNLNFBMNxTyUYkwWCcVlWFqz7BTN7lmBHOrNgveGcAtzh7ll3Xw/8J3BiwbZXu3uOYJiPdqAL6AVuMbOPAj1FtnkgwRDTAITbvRp4GPiyu+8yVr2ZfRPIALfnZxXZZuHx3g0Eh4xEhqUegVQbA/7Z3f+wy8zgXEL3kPdnACe5e4+ZPQI0jGDbw+krmM4CqfB4/hyCAdPOBy4DThvyuR1A85B57wA2MmQHHh7zPwc43Xee3NvbqJsN4e8QGZZ6BFLpthE8ojPvD8Dnw6G5MbPDLXiIy1DNwOYwBI5g10MwA/nPD/Eo8InwPEQbwVPDhh3h0oJnRDS7+/3AFQSHlYZaBhxa8Jk5wFkEh5q+Eo4yiZmdCXyd4KRyYc9i2FE3w/MU04BVw9UoAuoRSOVbDGTCQzw/Bq4jOCyzMNwRdlL8sX2/By4xs8UEIzkWHme/GVhsZgvd/b8WzP8NwXNhnyU4/PI1d38jDJJiJgG/NbMGgt7EF4us8yjwv8Na64AfAhe5+1oz+zLwIzM7jWBEyXrgwfA89JPufom7P2dmvyIYljoDXFpwRdQJ4XoZRPZAl4+KxMzMrgN+5+4PRbDde939T6XcrlQfHRoSid93CB7OXmpLFQIyEuoRiIjUOPUIRERqnIJARKTGKQhERJz5dx4AAAATSURBVGqcgkBEpMYpCEREatz/B6NqNOC7mTblAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studying [ 2.502647    0.8435674  -0.5512602   0.9125174   0.37532443]\n",
      "processing [-0.25741574  0.33540925 -2.3591557  -1.5930763   0.23177211]\n",
      "now [-0.86639297 -0.49735793  2.2491784  -0.8152124   1.2367994 ]\n",
      "i [ 0.00022748  0.01769666 -0.01410401 -0.00871453  0.01188387]\n",
      "am [-1.871323   -0.3422268   0.23711266  1.8859692  -1.0136672 ]\n",
      ". [ 0.00796106 -0.0018851   0.01208456  0.00678389 -0.00122144]\n",
      "natural [-1.0098052  -1.4723448  -1.6700692  -0.20425095 -1.910571  ]\n",
      "language [ 1.8665076   0.90065134  2.329075   -0.43108365  0.22821839]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "### <your code> ###\n",
    "word_vecs = skip_gram.word_vecs\n",
    "for word_id, word in idx2word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
