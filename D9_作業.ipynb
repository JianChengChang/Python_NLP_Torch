{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBNAC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=True, dropout=0.3, is_output=False):\n",
    "        super(LinearBNAC, self).__init__()\n",
    "        if is_output and out_channels==1:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(in_channels, out_channels, bias=bias),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        elif is_output:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(in_channels, out_channels, bias=bias),\n",
    "                nn.Softmax(dim=1)\n",
    "            )   \n",
    "        else:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(in_channels, out_channels, bias=bias),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.LeakyReLU(inplace=True)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out=self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dimention, output_classes=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = LinearBNAC(input_dimention, 128)\n",
    "        self.layer2 = LinearBNAC(128,64)\n",
    "        self.layer3 = LinearBNAC(64,32)\n",
    "        self.output = LinearBNAC(32, output_classes, is_output=True)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.output(x)\n",
    "        return x \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備輸入資料、優化器、標籤資料、模型輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dimention=256,output_classes=10)\n",
    "optimizer = optim.Adam(params=model.parameters(),lr=0.0001,weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-33345e58fff8>:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  target = torch.tensor([9., 5., 4., 4.], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "input_features = 256\n",
    "dummy_input = torch.randn(batch_size, input_features,)\n",
    "\n",
    "#target = torch.empty(4, dtype=torch.float).random_(10)\n",
    "target = torch.tensor([9., 5., 4., 4.], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0968, 0.0797, 0.0657, 0.0561, 0.1106, 0.1306, 0.1013, 0.1498, 0.1224,\n",
      "         0.0870],\n",
      "        [0.0704, 0.1385, 0.0385, 0.0480, 0.0730, 0.1364, 0.0681, 0.1426, 0.1150,\n",
      "         0.1696],\n",
      "        [0.1311, 0.0732, 0.0636, 0.0429, 0.0639, 0.1458, 0.0634, 0.1151, 0.1528,\n",
      "         0.1481],\n",
      "        [0.0902, 0.0755, 0.0718, 0.0723, 0.0686, 0.2033, 0.0643, 0.0836, 0.1387,\n",
      "         0.1316]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = model(dummy_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算 CrossEntropy Loss\n",
    "* 請注意哪一個 Loss最適合：我們已經使用 softmax\n",
    "* 因為我們有使用dropout，並隨機產生dummy_input，所以各為學員得到的值會與解答不同，然而步驟原理需要相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import NLLLoss, LogSoftmax, CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(torch.log(output), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4658, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完成back propagation並更新梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : Parameter containing:\n",
      "tensor([[ 0.0213,  0.0239,  0.0573,  ...,  0.0454,  0.0524,  0.0299],\n",
      "        [-0.0435, -0.0203, -0.0312,  ..., -0.0117, -0.0064,  0.0396],\n",
      "        [-0.0031,  0.0590,  0.0119,  ...,  0.0340, -0.0537, -0.0040],\n",
      "        ...,\n",
      "        [-0.0300, -0.0106,  0.0465,  ..., -0.0619,  0.0026, -0.0508],\n",
      "        [ 0.0477,  0.0163, -0.0578,  ..., -0.0364,  0.0555,  0.0344],\n",
      "        [ 0.0069, -0.0383, -0.0213,  ..., -0.0005,  0.0340,  0.0373]],\n",
      "       requires_grad=True)\n",
      "\n",
      "\n",
      "grad : tensor([[-0.0013, -0.0007,  0.0002,  ...,  0.0006,  0.0006,  0.0029],\n",
      "        [ 0.0151, -0.0028, -0.0037,  ..., -0.0077, -0.0288, -0.0791],\n",
      "        [-0.0057, -0.0225,  0.0098,  ...,  0.0090, -0.0262, -0.0244],\n",
      "        ...,\n",
      "        [-0.0152, -0.0291,  0.0116,  ...,  0.0199, -0.0271, -0.0048],\n",
      "        [ 0.0157,  0.0250, -0.0181,  ...,  0.0069, -0.0009, -0.0269],\n",
      "        [-0.0156,  0.0363, -0.0464,  ..., -0.0533,  0.0614,  0.0147]])\n"
     ]
    }
   ],
   "source": [
    "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
    "print('\\n')\n",
    "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : Parameter containing:\n",
      "tensor([[ 0.0214,  0.0240,  0.0572,  ...,  0.0453,  0.0523,  0.0298],\n",
      "        [-0.0436, -0.0202, -0.0311,  ..., -0.0116, -0.0063,  0.0397],\n",
      "        [-0.0030,  0.0591,  0.0118,  ...,  0.0339, -0.0536, -0.0039],\n",
      "        ...,\n",
      "        [-0.0299, -0.0105,  0.0464,  ..., -0.0620,  0.0027, -0.0507],\n",
      "        [ 0.0476,  0.0162, -0.0577,  ..., -0.0365,  0.0556,  0.0345],\n",
      "        [ 0.0070, -0.0384, -0.0212,  ..., -0.0004,  0.0339,  0.0372]],\n",
      "       requires_grad=True)\n",
      "\n",
      "\n",
      "grad : tensor([[-0.0013, -0.0007,  0.0002,  ...,  0.0006,  0.0006,  0.0029],\n",
      "        [ 0.0151, -0.0028, -0.0037,  ..., -0.0077, -0.0288, -0.0791],\n",
      "        [-0.0057, -0.0225,  0.0098,  ...,  0.0090, -0.0262, -0.0244],\n",
      "        ...,\n",
      "        [-0.0152, -0.0291,  0.0116,  ...,  0.0199, -0.0271, -0.0048],\n",
      "        [ 0.0157,  0.0250, -0.0181,  ...,  0.0069, -0.0009, -0.0269],\n",
      "        [-0.0156,  0.0363, -0.0464,  ..., -0.0533,  0.0614,  0.0147]])\n"
     ]
    }
   ],
   "source": [
    "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
    "print('\\n')\n",
    "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清空 gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : Parameter containing:\n",
      "tensor([[ 0.0214,  0.0240,  0.0572,  ...,  0.0453,  0.0523,  0.0298],\n",
      "        [-0.0436, -0.0202, -0.0311,  ..., -0.0116, -0.0063,  0.0397],\n",
      "        [-0.0030,  0.0591,  0.0118,  ...,  0.0339, -0.0536, -0.0039],\n",
      "        ...,\n",
      "        [-0.0299, -0.0105,  0.0464,  ..., -0.0620,  0.0027, -0.0507],\n",
      "        [ 0.0476,  0.0162, -0.0577,  ..., -0.0365,  0.0556,  0.0345],\n",
      "        [ 0.0070, -0.0384, -0.0212,  ..., -0.0004,  0.0339,  0.0372]],\n",
      "       requires_grad=True)\n",
      "\n",
      "\n",
      "grad : tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
    "print('\\n')\n",
    "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
